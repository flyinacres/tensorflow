{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://keras.io/guides/keras_nlp/getting_started/","metadata":{}},{"cell_type":"code","source":"!pip install -q --upgrade keras-nlp\n!pip install -q --upgrade keras  # Upgrade to Keras 3.","metadata":{"execution":{"iopub.status.busy":"2024-07-23T02:39:28.546000Z","iopub.execute_input":"2024-07-23T02:39:28.546368Z","iopub.status.idle":"2024-07-23T02:40:03.368233Z","shell.execute_reply.started":"2024-07-23T02:39:28.546329Z","shell.execute_reply":"2024-07-23T02:40:03.366792Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n\nimport keras_nlp\nimport keras\n\n# Use mixed precision to speed up all training in this guide.\nkeras.mixed_precision.set_global_policy(\"mixed_float16\")","metadata":{"execution":{"iopub.status.busy":"2024-07-23T02:40:44.184551Z","iopub.execute_input":"2024-07-23T02:40:44.185314Z","iopub.status.idle":"2024-07-23T02:41:00.193837Z","shell.execute_reply.started":"2024-07-23T02:40:44.185260Z","shell.execute_reply":"2024-07-23T02:41:00.192685Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-23 02:40:49.062373: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-23 02:40:49.062489: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-23 02:40:49.267054: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n!tar -xf aclImdb_v1.tar.gz\n!# Remove unsupervised examples\n!rm -r aclImdb/train/unsup","metadata":{"execution":{"iopub.status.busy":"2024-07-23T02:41:39.028442Z","iopub.execute_input":"2024-07-23T02:41:39.029623Z","iopub.status.idle":"2024-07-23T02:42:23.422171Z","shell.execute_reply.started":"2024-07-23T02:41:39.029585Z","shell.execute_reply":"2024-07-23T02:42:23.420615Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 80.2M  100 80.2M    0     0  2491k      0  0:00:32  0:00:32 --:--:-- 2664k\n","output_type":"stream"}]},{"cell_type":"code","source":"BATCH_SIZE = 16\nimdb_train = keras.utils.text_dataset_from_directory(\n    \"aclImdb/train\",\n    batch_size=BATCH_SIZE,\n)\nimdb_test = keras.utils.text_dataset_from_directory(\n    \"aclImdb/test\",\n    batch_size=BATCH_SIZE,\n)\n\n# Inspect first review\n# Format is (review text tensor, label tensor)\nprint(imdb_train.unbatch().take(1).get_single_element())","metadata":{"execution":{"iopub.status.busy":"2024-07-23T02:42:49.362365Z","iopub.execute_input":"2024-07-23T02:42:49.362793Z","iopub.status.idle":"2024-07-23T02:42:53.974101Z","shell.execute_reply.started":"2024-07-23T02:42:49.362757Z","shell.execute_reply":"2024-07-23T02:42:53.972916Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 25000 files belonging to 2 classes.\nFound 25000 files belonging to 2 classes.\n(<tf.Tensor: shape=(), dtype=string, numpy=b'We went into this movie because my husband had enjoyed the original version of `My favourite Martian\\'. We had our 6 year old daughter with us. She wanted to leave halfway through the movie which was fine with both her parents! The parts we did see were only occasionally humorous, mostly either too silly or gross. I would expect that this movie might appeal to kids between 9-12, if that. It\\'s definitely not suited for younger children. From what I\\'ve heard the original series was by far superior and if you are going to \"relive the past\" you\\'ll probably be disappointed.'>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"classifier = keras_nlp.models.BertClassifier.from_preset(\"bert_tiny_en_uncased_sst2\")\n# Note: batched inputs expected so must wrap string in iterable\nclassifier.predict([\"I love modular workflows in keras-nlp!\"])","metadata":{"execution":{"iopub.status.busy":"2024-07-23T02:43:03.636399Z","iopub.execute_input":"2024-07-23T02:43:03.636811Z","iopub.status.idle":"2024-07-23T02:43:36.812689Z","shell.execute_reply.started":"2024-07-23T02:43:03.636784Z","shell.execute_reply":"2024-07-23T02:43:36.811636Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Attaching 'model.safetensors' from model 'keras/bert/keras/bert_tiny_en_uncased_sst2/4' to your Kaggle notebook...\nAttaching 'model.safetensors.index.json' from model 'keras/bert/keras/bert_tiny_en_uncased_sst2/4' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/bert/keras/bert_tiny_en_uncased_sst2/4' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/bert/keras/bert_tiny_en_uncased_sst2/4' to your Kaggle notebook...\nAttaching 'task.json' from model 'keras/bert/keras/bert_tiny_en_uncased_sst2/4' to your Kaggle notebook...\nAttaching 'task.json' from model 'keras/bert/keras/bert_tiny_en_uncased_sst2/4' to your Kaggle notebook...\nAttaching 'task.json' from model 'keras/bert/keras/bert_tiny_en_uncased_sst2/4' to your Kaggle notebook...\nAttaching 'task.json' from model 'keras/bert/keras/bert_tiny_en_uncased_sst2/4' to your Kaggle notebook...\nAttaching 'task.weights.h5' from model 'keras/bert/keras/bert_tiny_en_uncased_sst2/4' to your Kaggle notebook...\nAttaching 'task.weights.h5' from model 'keras/bert/keras/bert_tiny_en_uncased_sst2/4' to your Kaggle notebook...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 4 variables whereas the saved optimizer has 84 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 0 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"},{"name":"stdout","text":"Attaching 'model.weights.h5' from model 'keras/bert/keras/bert_tiny_en_uncased_sst2/4' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.txt' from model 'keras/bert/keras/bert_tiny_en_uncased_sst2/4' to your Kaggle notebook...\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array([[-1.287,  1.393]], dtype=float16)"},"metadata":{}}]},{"cell_type":"code","source":"classifier.evaluate(imdb_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T02:44:03.112694Z","iopub.execute_input":"2024-07-23T02:44:03.113658Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\u001b[1m 194/1563\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:27\u001b[0m 458ms/step - loss: 0.4493 - sparse_categorical_accuracy: 0.7960","output_type":"stream"}]}]}